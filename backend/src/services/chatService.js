import { MemoryService } from './memoryService.js';
import { generateChatResponse } from './geminiService.js';
import fetch from 'node-fetch';
import TopicAnalyzer from './topicAnalyzer.js';
import axios from 'axios';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { config, initializeConfig } from '../config/index.js';
import { 
  BASE_THERAPIST_PROMPT,
  INTRO_PROMPT,
  WELCOME_BACK_PROMPT,
  ONBOARDING_PROMPT,
  PERSONAL_CONVO_PROMPT
} from './prompts.js';

// Ensure the configuration is loaded before using it
await initializeConfig();
const AI_IDENTIFYING_KEYWORDS = [
  'ai',
  'google',
  'gemini',
  'llm',
  'language model',
  'large model',  
  'openai',
  'chatgpt',
  'machine learning',
  'neural network',
  'deep learning',
  'automated system',
  'digital assistant',
  'virtual assistant',
  'algorithm',
  'bot',
  'human'
];

const genAI = new GoogleGenerativeAI(config.gemini.apiKey);
function shouldIncludeNameInContext(sessionMemory, userName) {
  if (!userName) return false;
  
  // Only include name in roughly 15% of messages
  const randomChance = Math.random() < 0.15;
  
  // Count recent messages to avoid consecutive name usage
  const recentMessages = sessionMemory.chat_context
    .filter(msg => msg.role === 'assistant')
    .slice(-3); // Look at last 3 assistant messages
  
  // Check if name was used in recent messages
  const namePattern = new RegExp(`\\b${userName}\\b`, 'i');
  const nameUsedRecently = recentMessages.some(msg => 
    namePattern.test(msg.content)
  );
  
  // Only include name if random chance hits AND name wasn't used recently
  return randomChance && !nameUsedRecently;
}
function containsAITerm(text) {
  if (!text) {
      return false;
  }
  const lowerCaseText = text.toLowerCase();
  return AI_IDENTIFYING_KEYWORDS.some(keyword => lowerCaseText.includes(keyword));
}
async function refineResponse(originalResponse) {
  try {
      const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
      const prompt = `Please rewrite the following response from a therapy session to sound like it's coming directly from a human therapist. Ensure it is empathetic, professional, and avoids any language that identifies it as being generated by an AI. Remove any phrases like "${AI_IDENTIFYING_KEYWORDS.join('", "')}" or similar self-referential statements.

Original Response:
${originalResponse}

Refined Response:`;

      const result = await model.generateContent(prompt);
      const refinedText = result.response.text().trim();
      return refinedText;
  } catch (error) {
      console.error('Error refining response:', error);
      return originalResponse; // Return the original response in case of an error
  }
}
async function refineWithGemini(text) {
  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
    const prompt = `Make this therapy response sound naturally human. Keep the meaning intact, but add subtle human elements (occasional filler words, natural phrasing, slight informality). Don't overdo it - aim for subtle authenticity rather than obvious changes. Return only the refined text.Let the slight imperfections remain there.

Original text:
${text}`;

    const result = await model.generateContent(prompt);
    const refinedText = result.response.text().trim();
    return refinedText;
  } catch (error) {
    console.error('Error refining with Gemini:', error);
    return text; // Return original text if refinement fails
  }
}

async function humanizeResponse(response) {
  let modifications = 0;
  const MAX_MODIFICATIONS = 2;
  // Typo injection
  if (modifications < MAX_MODIFICATIONS && Math.random() < 0.2) {
    const words = response.split(' ');
    const idx = Math.floor(Math.random() * words.length);
    const word = words[idx];
    if (word && word.length > 4) {
      const typoType = Math.floor(Math.random() * 2);
      let newWord = word;
      if (typoType === 0) {
        const pos = Math.floor(Math.random() * (word.length - 2)) + 1;
        newWord = word.substring(0, pos) + word[pos + 1] + word[pos] + word.substring(pos + 2);
      } else {
        const pos = Math.floor(Math.random() * (word.length - 1));
        newWord = word.substring(0, pos) + word[pos] + word.substring(pos);
      }
      words[idx] = newWord;
      response = words.join(' ');
      modifications++;
    }
  }
  // Punctuation change
  if (modifications < MAX_MODIFICATIONS && Math.random() < 0.2) {
    response = response.replace(/\.\s+([A-Z])/g, (_, p1) => {
      if (Math.random() < 0.4) {
        return ', and ' + p1.toLowerCase();
      }
      return '. ' + p1;
    });
    modifications++;
  }
  // Filler insertion
  if (modifications < MAX_MODIFICATIONS && Math.random() < 0.2) {
    const fillers = ['like', 'um', 'you know', 'I mean', 'actually'];
    const sentences = response.split(/(?<=[.!?])\s+/);
    let inserted = false;
    for (let i = 0; i < sentences.length; i++) {
      if (inserted) break;
      if (Math.random() < 0.3 && sentences[i].length > 15) {
        const words = sentences[i].split(' ');
        const filler = fillers[Math.floor(Math.random() * fillers.length)];
        const pos = Math.min(2, words.length - 1);
        words.splice(pos, 0, filler);
        sentences[i] = words.join(' ');
        inserted = true;
        modifications++;
      }
    }
    response = sentences.join(' ');
  }
  // Final refinement using Gemini
  const original = response;
// ... all modification logic
if (response === original) {
  return response; // skip Gemini call
}
  const refined = await refineWithGemini(response);
  return refined;
}
export class ChatService {
  static async processMessage(userId, sessionId, message) {
    console.log(`Processing message for User: ${userId}, Session: ${sessionId}`);
    console.log(`Message Content: ${message || 'EMPTY (Auto Welcome)'}`);

    try {
      // Get session context
      let sessionMemory = await MemoryService.getSessionMemory(sessionId);
      let isFirstInteraction = false;
      let isOnboarding = false;
      let isWelcomeBack = false;
      let isAutoWelcome = !message || message.trim() === ''; // Check if this is an auto welcome (empty message)
      let customPrompt = BASE_THERAPIST_PROMPT;
      let userName = null;

      // Get user profile data if it exists
      const userProfile = await MemoryService.getUserProfile(userId);

      // Check if this is a brand new user with no history
      if (!sessionMemory || !sessionMemory.chat_context) {
        console.log(`Creating new session memory for Session: ${sessionId}`);
        sessionMemory = {
          session_id: sessionId,
          user_id: userId,
          chat_context: []
        };
      }
        
        // If user has no profile, this is the first interaction ever
      if (!userProfile || !userProfile.name) {
        isFirstInteraction = true;
        customPrompt = INTRO_PROMPT;
        console.log('First interaction detected, using introduction prompt');
      }
      
      
      // Check if we're in the onboarding phase (user has started but not completed profile)
      if (userProfile && userProfile.name && !userProfile.onboardingComplete) {
        isOnboarding = true;
        userName = userProfile.name;
        customPrompt = ONBOARDING_PROMPT.replace('{userName}', userName);
        console.log(`Onboarding phase for user ${userName}`);
      } 
      // If user has a complete profile, use personalized prompt
      else if (userProfile && userProfile.name && userProfile.onboardingComplete) {
        userName = userProfile.name;
        
        // If this is an auto welcome call for a returning user, use the welcome back prompt
        if (isAutoWelcome) {
          isWelcomeBack = true;
          customPrompt = WELCOME_BACK_PROMPT.replace('{userName}', userName);
          console.log(`Welcome back trigger for returning user ${userName}`);
        } else {
          customPrompt = BASE_THERAPIST_PROMPT;
          console.log(`Personalized conversation for returning user ${userName}`);
        }
      }

      // Only add user message to context if it's not an auto welcome
      
        sessionMemory.chat_context.push({
          role: 'user',
          content: message
        });
      

      console.log(`Current Chat Context Length: ${sessionMemory.chat_context.length}`);

      // For first-time users, don't query memory since there isn't any
      let relevantMemories = [];
      let relevantContext = '';
      
      if (!isFirstInteraction && !isOnboarding && !isWelcomeBack && !isAutoWelcome) {
        // Only query memory for actual user messages, not auto welcomes
        // Query long-term memory for relevant context
        console.log(`Querying Long-Term Memory for User: ${userId}`);
        relevantMemories = await MemoryService.queryLongTermMemory(
          userId,
          message
        );

        console.log(`Found ${relevantMemories.length} Relevant Memories`);
        relevantContext = this.formatContextFromMemories(relevantMemories);
      }

      // Add system message with relevant memories if any
      let contextWithMemories = [...sessionMemory.chat_context];
      if (relevantContext) {
        console.log(`Adding Relevant Memory Context: ${relevantContext}`);
        contextWithMemories.unshift({
          role: 'user', // Using 'user' role for context injection seems to work well with Gemini
          content: `Relevant past information: ${relevantContext}`
        });
      }

      // Enhanced user profile handling - Make the importance of this data more explicit
      if (userName) {
        const shouldIncludeName = shouldIncludeNameInContext(sessionMemory, userName);
        
        let userInfo = `[CRITICAL CLIENT INFORMATION ]
The client's name is: ${userName}. Use their name some times (30 percent) in your responses.`;
if (shouldIncludeName) {
  userInfo += ` Use their name once in your response in a natural way.`;
  console.log(`Including instruction to use ${userName}'s name in this response`);
} else {
  userInfo = ` DO NOT use their name in this response.`;
  console.log(`Excluding name usage for this response`);
}
        
        const profileSummary = userProfile.onboardingSummary 
          ? `\n\n[CLIENT PROFILE - ESSENTIAL CONTEXT]
${userProfile.onboardingSummary}

[INSTRUCTIONS FOR USING PROFILE DATA]
- Reference specific details from this profile in your responses
- Tailor your therapeutic approach based on the client's age, gender, occupation, and concerns
- Remember their history and previous challenges when providing guidance
- Use this information to personalize metaphors, examples, and solutions
- Show you remember who they are through subtle references to their background`
          : '';
          
        contextWithMemories.unshift({
          role: 'user',
          content: userInfo + profileSummary
        });
      }

      // Generate response with full context using the appropriate prompt
      console.log(`Generating ${isAutoWelcome ? 'Auto Welcome' : 'Chat'} Response with ${isFirstInteraction ? 'intro' : isWelcomeBack ? 'welcome back' : isOnboarding ? 'onboarding' : 'standard'} prompt`);
      
      // For auto welcome, we pass an empty message
      const userMessage = isAutoWelcome ? '' : message;
      
      const response = await generateChatResponse(
        userMessage,
        contextWithMemories,
        customPrompt
      );
      let processedResponse = response;
      if (containsAITerm(response)) {
      console.log('AI identifying terms found in response. Refining...');
      processedResponse = await refineResponse(response);
      console.log(`Refined Response: ${processedResponse}`);
      } else {
      console.log('No AI identifying terms found in response.');
      }

      // Apply humanization regardless of whether AI terms were found
      console.log('Applying human-like modifications...');
      const finalResponse = await humanizeResponse(processedResponse);
      console.log(`Humanized Response: ${finalResponse}`);

      // Add AI response to context
      sessionMemory.chat_context.push({
        role: 'assistant',
        content: finalResponse
      });
      
      if (isFirstInteraction && !userProfile && !isAutoWelcome) {
        // Only try to extract names from actual user messages, not auto welcomes
        const extractedName = await this.extractUserName(message, finalResponse);
        if (extractedName) {
          console.log(`Extracted user name: ${extractedName}`);
          await MemoryService.saveUserProfile(userId, {
            name: extractedName,
            onboardingComplete: false,
            firstSessionDate: new Date().toISOString()
          });
          // Update userName for the current session
          userName = extractedName;
        }
      }
      
      // If in onboarding, check if we should mark onboarding as complete
      if (isOnboarding && sessionMemory.chat_context.length >= 10) {
        console.log(`Marking onboarding as complete for user ${userName}`);
        
        // Generate a summary of key information learned during onboarding
        const onboardingSummary = await this.generateOnboardingSummary(sessionMemory.chat_context, userName);
        
        await MemoryService.updateUserProfile(userId, { 
          onboardingComplete: true,
          onboardingSummary: onboardingSummary
        });
      }

      // Save updated session memory
      console.log(`Saving Session Memory for Session: ${sessionId}`);
      await MemoryService.saveSessionMemory(
        sessionId,
        userId,
        sessionMemory.chat_context
      );

      // Summarize the context and potentially save to long-term memory
      // Skip summarization for auto welcome messages since they're not actual interactions
      if (sessionMemory.chat_context.length > 20 && !isAutoWelcome) {
        const isSummarizing = true; // Flag to indicate summarization
        console.log(`Context length > 10, attempting summarization for Session: ${sessionId}`);

        // Perform summarization
        const summarizedContext = await MemoryService.summarizeConversation(sessionMemory.chat_context);

        // Check if summarization actually changed the context (it might return original if too short)
        if (summarizedContext !== sessionMemory.chat_context) {
          sessionMemory.chat_context = summarizedContext;
          console.log(`Summarization complete. New context length: ${sessionMemory.chat_context.length}`);

          // Save the new summarized context back to Redis
          await MemoryService.saveSessionMemory(sessionId, userId, sessionMemory.chat_context);

          // Save to long-term memory only after successful summarization
          if (this.shouldSaveToLongTerm(isSummarizing, message, finalResponse)) {
            console.log(`Saving summarized interaction to long-term memory for User: ${userId}`);
            const mood = await TopicAnalyzer.analyzeMood(message); // Analyze original user message
            const topic = await TopicAnalyzer.analyzeTopic(message); // Analyze original user message
            console.log(`Determined Mood: ${mood}, Topic: ${topic}`);
            await MemoryService.saveLongTermMemory(userId, {
              content: message, // Original user message
              response: finalResponse, // AI response to that message
              type: 'summary_interaction', // Mark as part of a summarized interaction
              mood: mood,
              topic: topic
            });
          }
        } else {
          console.log(`Summarization skipped or failed for Session: ${sessionId}`);
        }
      }

      return {
        response: finalResponse,
        context: sessionMemory.chat_context // Return the potentially updated context
      };
      
    } catch (error) {
      console.error('Critical Error Processing Message:', error);
      console.error('Error Details:', {
        userId,
        sessionId,
        message: message ? message.substring(0, 100) + '...' : 'EMPTY (Auto Welcome)', // Avoid logging potentially large messages fully
        errorName: error.name,
        errorMessage: error.message,
        errorStack: error.stack // Include stack for better debugging
      });
      // Consider throwing a more user-friendly error or a specific error type
      throw new Error('Failed to process chat message due to an internal server error.');
    }
  }

  static formatContextFromMemories(memories) {
    console.log(`Formatting Context from ${memories ? memories.length : 0} Memories`);
    
    if (!memories || memories.length === 0) {
      return '';
    }
    
    return memories
      .map(memory => {
        const content = memory.metadata.content || "Unknown content";
        const topic = memory.metadata.topic || "general topic";
        const mood = memory.metadata.mood || "neutral mood";
        return `Previous interaction about ${topic}: ${content}: ${mood}`;
      })
      .join('\n');
  }

  static shouldSaveToLongTerm(isSummarizing, message, response) {
    return isSummarizing; // Properly return the boolean flag
  }

  static async extractUserName(userMessage, aiResponse) {
    try {
      // Skip name extraction for empty messages (auto welcomes)
      if (!userMessage || userMessage.trim() === '') {
        return null;
      }
      
      // Create a prompt to extract the name
      const extractPrompt = `
      Based on this conversation exchange, extract the user's name if they shared it.
      Only return the name, nothing else. If no name is found, return "NULL".
      
      User message: "${userMessage}"
      AI response: "${aiResponse}"
      `;
      
      const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
      const result = await model.generateContent(extractPrompt);
      const extractedText = result.response.text().trim();
      
      return extractedText === "NULL" ? null : extractedText;
    } catch (error) {
      console.error('Error extracting user name:', error);
      return null;
    }
  }
  
  static async generateOnboardingSummary(chatContext, userName) {
    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
    
    const summaryPrompt = `
    Based on this conversation with ${userName}, create a concise summary (150-200 words) of key information learned during their initial therapy sessions. 
    
    IMPORTANT: Make sure to explicitly include the following information if mentioned:
    1. Their age (exact number if mentioned)
    2. Their occupation/profession
    3. Their likely gender based on context and name (do not speculate if unclear)
    4. Primary concerns or goals they mentioned
    5. Notable emotional patterns or challenges
    6. Important life context (relationships, family situation, etc.)
    7. Previous coping strategies they've found helpful
    8. Communication preferences or response styles they seem to prefer
    
    Format as a professional clinical summary that captures essential context for future therapeutic conversations.
    The first sentence should specifically summarize demographic information (age, gender, occupation).
    
    Example first sentence: "${userName} is a 32-year-old female software engineer who is experiencing work-related stress."
    `;
    
    // Filter to just the conversation parts (not system messages)
    const conversationOnly = chatContext.filter(msg => 
      msg.role === 'user' || msg.role === 'assistant');
    
    const conversationText = conversationOnly.map(msg => 
      `${msg.role.toUpperCase()}: ${msg.content}`).join('\n\n');
    
    try {
      const result = await model.generateContent([summaryPrompt, conversationText]);
      const summary = result.response.text();
      console.log(`Generated onboarding summary for ${userName}`);
      return summary;
    } catch (error) {
      console.error('Error generating onboarding summary:', error);
      return `${userName} - Basic information captured during onboarding.`;
    }
  }
}